{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAT 4185 Final Project\n",
    "### Jacob Gratrix\n",
    "\n",
    "## An Analysis of the US Power Grid and its System Optimality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The United States power grid, while commercially balkanized among regional markets and operating firms, is the largest and most connected piece of infrastructure ever constructed by mankind. While the relationships between consumer satisfaction with grid operations and the actual upkeep status of the grid are no doubt complex, here we aim to ascertain the rough degree to which this infrastructure accomplishes its explicit goal. That is to provide electricity from where it is supplied to where it is demanded.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "We first import the relevant libraries for performing our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import several libraries for the data collection. These include the builtin `datetime` package and the `gridstatus` API for collating data from regional power operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gridstatus as gs\n",
    "import datetime as dt\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it is necessary to define a list of service operators, `interconnections`, for convenience of analysing multiple regions at once. \n",
    "Additionally, we define two functions, `get_fuel_mixes` and `get_grid_loads` to return Pandas DataFrames amenable to processing.\n",
    "\n",
    "We will use data from the current year, from a subset of the months of the year, and include data from just the first day of the month in order to keep the data volume manageable. \n",
    "\n",
    "Note that `interconnections` will not include the PJM, MISO, SPP, or Ercot regional system operators. This is because they either have no published fuel mix data for the dates requested, or don't support the fuel mix retrieval method in the `gridstatus` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "isone = gs.ISONE() # New England ISO\n",
    "caiso = gs.CAISO() # California ISO\n",
    "nyiso = gs.NYISO() # New York ISO\n",
    "pjm = gs.PJM() # PJM Interconnection RTO\n",
    "miso = gs.MISO() # Midcontinent ISO\n",
    "spp = gs.SPP() # Southwest Power Pool RTO\n",
    "ercot = gs.Ercot() # Electric Reliability Council, Texas\n",
    "\n",
    "interconnections = [isone, caiso, nyiso] # Excluded: PJM, MISO, SPP, Ercot\n",
    "\n",
    "months = ['January', 'March', 'May', 'July', 'September', 'November']\n",
    "\n",
    "def get_fuel_mixes(iso):\n",
    "    fuel_mixes = {}\n",
    "    for mo in months:\n",
    "        start = pd.Timestamp(f'{mo} 1, 2022')\n",
    "        end = pd.Timestamp(f'{mo} 2, 2022') # We'll only use one day each month to keep amt of data manageable\n",
    "        fuel_mix = iso.get_fuel_mix(start, verbose=False)\n",
    "        fuel_mixes[mo] = fuel_mix\n",
    "    return fuel_mixes\n",
    "\n",
    "def get_grid_loads(iso):\n",
    "    grid_loads = {}\n",
    "    for mo in months:\n",
    "        start = pd.Timestamp(f'{mo} 1, 2022')\n",
    "        end = pd.Timestamp(f'{mo} 2, 2022') # We'll only use one day each month to keep amt of data manageable\n",
    "        grid_load = iso.get_load(start)\n",
    "        grid_loads[mo] = grid_load\n",
    "    return grid_loads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these functions, we obtain our fuel mix data and grid load data for the first day in the first odd months of 2022. \n",
    "Please note that this cell takes upwards of 90 seconds to run. As an alternative, two cells down it is coded to initialize the dataframes from `.csv` files containing the data accompanying this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "mix_dfs = {}\n",
    "load_dfs = {}\n",
    "\n",
    "for iso in interconnections:\n",
    "    mix_dfs[iso] = get_fuel_mixes(iso)\n",
    "    load_dfs[iso] = get_grid_loads(iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iso in interconnections:\n",
    "    for mo in months:\n",
    "        mix_output = pd.DataFrame(mix_dfs[iso][mo])\n",
    "        mix_output.to_csv(path_or_buf=f'./data/mix-{repr(iso)[12:16]}-{mo}', index=False)\n",
    "        load_output = pd.DataFrame(load_dfs[iso][mo])\n",
    "        load_output.to_csv(path_or_buf=f'./data/load-{repr(iso)[12:16]}-{mo}', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell may be used if the `./data` folder is accessible in your directory to generate the relevant Pandas dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_dfs = {}\n",
    "load_dfs = {}\n",
    "\n",
    "for iso in interconnections:\n",
    "    iso_str = repr(iso)[12:16]\n",
    "    mix_dfs[iso] = {}\n",
    "    load_dfs[iso] = {}\n",
    "    for mo in months:\n",
    "        mix_dfs[iso][mo] = pd.read_csv(f'./data/mix-{iso_str}-{mo}.csv')\n",
    "        load_dfs[iso][mo] = pd.read_csv(f'./data/load-{iso_str}-{mo}.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Munging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Visualizations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b85c235fe83537ff910f7c3e96f0f6da5d2d89c734ad1b409e7f42424359a87b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
